# OpenAI API Configuration
# API キーは .env.secrets ファイルに記載してください
# OPENAI_API_KEY は .env.secrets から読み込まれます
# OPENAI_MODEL の選択肢: gpt-5-nano, gpt-4o-mini, gpt-4o, gpt-3.5-turbo
OPENAI_MODEL=gpt-4o-mini

# Training Configuration
BASE_MODEL=Qwen/Qwen3-0.6B
MAX_LENGTH=512
BATCH_SIZE=4
LEARNING_RATE=2e-4
NUM_EPOCHS=100  # 最初のiterationのエポック数
NUM_EPOCHS_FOLLOWUP=20  # 2回目以降のiterationのエポック数

# LoRA Configuration
LORA_R=8
LORA_ALPHA=16
LORA_DROPOUT=0.1

# Evaluation Configuration
EVAL_BATCH_SIZE=10
NUM_EVAL_SAMPLES=15  # 仕様書準拠: 15問
NUM_SAMPLES_PER_QUESTION=1  # 各質問あたりのサンプリング回数（1=約2.5分、30=約75分）

# Baseline Evaluation (デフォルト: 無効)
# 注意: Qwen 0.6Bは医療知識がほぼゼロで、評価コスト(OpenAI API)が無駄になるため無効化を推奨
# 論文やレポートでベースラインスコアが必要な場合のみ true に設定してください
ENABLE_BASELINE=false

# Iteration Settings
ITERATIONS=2  # 初回学習後の反復回数
OUTPUT_DIR=results
REHEARSAL_RATIO=3.0  # 誤答数に対する成功例リハーサルデータの比率（正答ケースから何倍サンプリングするか）
